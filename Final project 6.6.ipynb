{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section Project:\n",
    "# For the final project for this section, you're going to train a DP model using this PATE method on the MNIST dataset, provided below.\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import helper\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12af26e48>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# *********** Load the data **********\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True,  download=True, transform=transform)\n",
    "mnist_testset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(mnist_trainset,batch_size=1, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(mnist_testset,batch_size=1)\n",
    "\n",
    "# *********** Check the data **********\n",
    "img, label = next(iter(testloader))\n",
    "helper.imshow(img[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# *********** Part from the exercise **********\n",
    "# TODO how can I use it?\n",
    "train_data = mnist_trainset.data\n",
    "train_targets = mnist_trainset.targets\n",
    "\n",
    "print(train_data.shape)\n",
    "\n",
    "test_data = mnist_testset.data\n",
    "test_targets = mnist_testset.targets\n",
    "\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_examples: 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *********** Prepare input for PATH analysis **********\n",
    "num_teachers = 100\n",
    "num_examples = len(mnist_testset)\n",
    "num_labels = 10\n",
    "\n",
    "lengths  = [len(mnist_trainset)//num_teachers]*num_teachers\n",
    "trainsets = torch.utils.data.random_split(mnist_trainset, lengths)\n",
    "\n",
    "print('num_examples:', num_examples)\n",
    "len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********** Create the model **********\n",
    "from collections import OrderedDict\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('fc1',  nn.Linear(784, 512)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('drop', nn.Dropout(p=0.2)),\n",
    "    ('fc2',  nn.Linear(512, 128)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('fc3',  nn.Linear(128, 10)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset: 1\n",
      "Training loss: 0.009065991640090943\n",
      "Test loss: 0.5354745752453804\n",
      "Accuracy: 0.8405\n",
      "Pred shape: (10000,)\n",
      "Trainset: 2\n",
      "Training loss: 0.004999106422066689\n",
      "Test loss: 0.4560947495818138\n",
      "Accuracy: 0.8639\n",
      "Pred shape: (10000,)\n",
      "Trainset: 3\n",
      "Training loss: 0.004196941927075386\n",
      "Test loss: 0.37976614516973495\n",
      "Accuracy: 0.8843\n",
      "Pred shape: (10000,)\n",
      "Trainset: 4\n",
      "Training loss: 0.004449522078037262\n",
      "Test loss: 0.35352672218084336\n",
      "Accuracy: 0.8915\n",
      "Pred shape: (10000,)\n",
      "Trainset: 5\n",
      "Training loss: 0.004364485293626786\n",
      "Test loss: 0.3357378056645393\n",
      "Accuracy: 0.8957\n",
      "Pred shape: (10000,)\n",
      "Trainset: 6\n",
      "Training loss: 0.004103996932506561\n",
      "Test loss: 0.3688022726893425\n",
      "Accuracy: 0.884\n",
      "Pred shape: (10000,)\n",
      "Trainset: 7\n",
      "Training loss: 0.003914005383849144\n",
      "Test loss: 0.26416834944486617\n",
      "Accuracy: 0.921\n",
      "Pred shape: (10000,)\n",
      "Trainset: 8\n",
      "Training loss: 0.002401392966508865\n",
      "Test loss: 0.29502897292375563\n",
      "Accuracy: 0.9124\n",
      "Pred shape: (10000,)\n",
      "Trainset: 9\n",
      "Training loss: 0.003326192259788513\n",
      "Test loss: 0.29955294848680497\n",
      "Accuracy: 0.9096\n",
      "Pred shape: (10000,)\n",
      "Trainset: 10\n",
      "Training loss: 0.0020010192841291427\n",
      "Test loss: 0.259933957362175\n",
      "Accuracy: 0.9217\n",
      "Pred shape: (10000,)\n",
      "Trainset: 11\n",
      "Training loss: 0.0018914088904857635\n",
      "Test loss: 0.27123186106681824\n",
      "Accuracy: 0.9177\n",
      "Pred shape: (10000,)\n",
      "Trainset: 12\n",
      "Training loss: 0.002501417264342308\n",
      "Test loss: 0.2439613129377365\n",
      "Accuracy: 0.9243\n",
      "Pred shape: (10000,)\n",
      "Trainset: 13\n",
      "Training loss: 0.0016714260131120682\n",
      "Test loss: 0.22927560319900514\n",
      "Accuracy: 0.9308\n",
      "Pred shape: (10000,)\n",
      "Trainset: 14\n",
      "Training loss: 0.0018976139277219772\n",
      "Test loss: 0.2702139722824097\n",
      "Accuracy: 0.9173\n",
      "Pred shape: (10000,)\n",
      "Trainset: 15\n",
      "Training loss: 0.002157494053244591\n",
      "Test loss: 0.20898856443166733\n",
      "Accuracy: 0.936\n",
      "Pred shape: (10000,)\n",
      "Trainset: 16\n",
      "Training loss: 0.001211982659995556\n",
      "Test loss: 0.24647906758785249\n",
      "Accuracy: 0.9327\n",
      "Pred shape: (10000,)\n",
      "Trainset: 17\n",
      "Training loss: 0.0015590935051441194\n",
      "Test loss: 0.2189644117474556\n",
      "Accuracy: 0.9378\n",
      "Pred shape: (10000,)\n",
      "Trainset: 18\n",
      "Training loss: 0.002596533477306366\n",
      "Test loss: 0.23625891481637953\n",
      "Accuracy: 0.9314\n",
      "Pred shape: (10000,)\n",
      "Trainset: 19\n",
      "Training loss: 0.0016907365545630454\n",
      "Test loss: 0.2143992323279381\n",
      "Accuracy: 0.9372\n",
      "Pred shape: (10000,)\n",
      "Trainset: 20\n",
      "Training loss: 0.001655861645936966\n",
      "Test loss: 0.19550838686227798\n",
      "Accuracy: 0.9405\n",
      "Pred shape: (10000,)\n",
      "Trainset: 21\n",
      "Training loss: 0.0016187347322702407\n",
      "Test loss: 0.19419625321626663\n",
      "Accuracy: 0.941\n",
      "Pred shape: (10000,)\n",
      "Trainset: 22\n",
      "Training loss: 0.0016839192062616348\n",
      "Test loss: 0.20945283780097962\n",
      "Accuracy: 0.9379\n",
      "Pred shape: (10000,)\n",
      "Trainset: 23\n",
      "Training loss: 0.002304992347955704\n",
      "Test loss: 0.24251057125329972\n",
      "Accuracy: 0.9281\n",
      "Pred shape: (10000,)\n",
      "Trainset: 24\n",
      "Training loss: 0.0014614911898970604\n",
      "Test loss: 0.21306703906059266\n",
      "Accuracy: 0.9373\n",
      "Pred shape: (10000,)\n",
      "Trainset: 25\n",
      "Training loss: 0.0027226546481251717\n",
      "Test loss: 0.1829299075126648\n",
      "Accuracy: 0.9435\n",
      "Pred shape: (10000,)\n",
      "Trainset: 26\n",
      "Training loss: 0.0011153520047664641\n",
      "Test loss: 0.21285307118892668\n",
      "Accuracy: 0.9408\n",
      "Pred shape: (10000,)\n",
      "Trainset: 27\n",
      "Training loss: 0.001230853222310543\n",
      "Test loss: 0.2079802195906639\n",
      "Accuracy: 0.9403\n",
      "Pred shape: (10000,)\n",
      "Trainset: 28\n",
      "Training loss: 0.002037605509161949\n",
      "Test loss: 0.18711646966934203\n",
      "Accuracy: 0.9429\n",
      "Pred shape: (10000,)\n",
      "Trainset: 29\n",
      "Training loss: 0.0014668388739228248\n",
      "Test loss: 0.18666990259885788\n",
      "Accuracy: 0.946\n",
      "Pred shape: (10000,)\n",
      "Trainset: 30\n",
      "Training loss: 0.0013033724054694175\n",
      "Test loss: 0.19114795995950698\n",
      "Accuracy: 0.9434\n",
      "Pred shape: (10000,)\n",
      "Trainset: 31\n",
      "Training loss: 0.0008723149597644806\n",
      "Test loss: 0.17251221570968628\n",
      "Accuracy: 0.9486\n",
      "Pred shape: (10000,)\n",
      "Trainset: 32\n",
      "Training loss: 0.0010985826849937439\n",
      "Test loss: 0.17582352098226547\n",
      "Accuracy: 0.9505\n",
      "Pred shape: (10000,)\n",
      "Trainset: 33\n",
      "Training loss: 0.001028515376150608\n",
      "Test loss: 0.18745528810024262\n",
      "Accuracy: 0.9475\n",
      "Pred shape: (10000,)\n",
      "Trainset: 34\n",
      "Training loss: 0.0011347509436309337\n",
      "Test loss: 0.18869651871919632\n",
      "Accuracy: 0.9488\n",
      "Pred shape: (10000,)\n",
      "Trainset: 35\n",
      "Training loss: 0.001956481559202075\n",
      "Test loss: 0.17614666011333466\n",
      "Accuracy: 0.9477\n",
      "Pred shape: (10000,)\n",
      "Trainset: 36\n",
      "Training loss: 0.0013575379401445388\n",
      "Test loss: 0.17961090215444564\n",
      "Accuracy: 0.9488\n",
      "Pred shape: (10000,)\n",
      "Trainset: 37\n",
      "Training loss: 0.001183388352394104\n",
      "Test loss: 0.1802907071709633\n",
      "Accuracy: 0.9484\n",
      "Pred shape: (10000,)\n",
      "Trainset: 38\n",
      "Training loss: 0.0009725047796964645\n",
      "Test loss: 0.17803618261814116\n",
      "Accuracy: 0.9499\n",
      "Pred shape: (10000,)\n",
      "Trainset: 39\n",
      "Training loss: 0.0008753493279218674\n",
      "Test loss: 0.17739033476114274\n",
      "Accuracy: 0.9521\n",
      "Pred shape: (10000,)\n",
      "Trainset: 40\n",
      "Training loss: 0.0016411520838737488\n",
      "Test loss: 0.20141936351060868\n",
      "Accuracy: 0.9442\n",
      "Pred shape: (10000,)\n",
      "Trainset: 41\n",
      "Training loss: 0.0016861061379313468\n",
      "Test loss: 0.16450944938659667\n",
      "Accuracy: 0.9532\n",
      "Pred shape: (10000,)\n",
      "Trainset: 42\n",
      "Training loss: 0.0016265574842691422\n",
      "Test loss: 0.16210416588783264\n",
      "Accuracy: 0.9521\n",
      "Pred shape: (10000,)\n",
      "Trainset: 43\n",
      "Training loss: 0.0011605557799339295\n",
      "Test loss: 0.1737465783238411\n",
      "Accuracy: 0.9506\n",
      "Pred shape: (10000,)\n",
      "Trainset: 44\n",
      "Training loss: 0.0017540460005402564\n",
      "Test loss: 0.1885083085179329\n",
      "Accuracy: 0.9465\n",
      "Pred shape: (10000,)\n",
      "Trainset: 45\n",
      "Training loss: 0.0010157076166942716\n",
      "Test loss: 0.16035976741313934\n",
      "Accuracy: 0.9579\n",
      "Pred shape: (10000,)\n",
      "Trainset: 46\n",
      "Training loss: 0.0018904655799269676\n",
      "Test loss: 0.16760945830345153\n",
      "Accuracy: 0.9506\n",
      "Pred shape: (10000,)\n",
      "Trainset: 47\n",
      "Training loss: 0.0016048970744013786\n",
      "Test loss: 0.17590561774969102\n",
      "Accuracy: 0.9501\n",
      "Pred shape: (10000,)\n",
      "Trainset: 48\n",
      "Training loss: 0.00096028121560812\n",
      "Test loss: 0.15724847544431686\n",
      "Accuracy: 0.9585\n",
      "Pred shape: (10000,)\n",
      "Trainset: 49\n",
      "Training loss: 0.0014234773516654969\n",
      "Test loss: 0.15981445162296296\n",
      "Accuracy: 0.9538\n",
      "Pred shape: (10000,)\n",
      "Trainset: 50\n",
      "Training loss: 0.0010019088461995125\n",
      "Test loss: 0.16592462730407714\n",
      "Accuracy: 0.9562\n",
      "Pred shape: (10000,)\n",
      "Trainset: 51\n",
      "Training loss: 0.001636732555925846\n",
      "Test loss: 0.17784950571060182\n",
      "Accuracy: 0.9481\n",
      "Pred shape: (10000,)\n",
      "Trainset: 52\n",
      "Training loss: 0.0015962682738900184\n",
      "Test loss: 0.17175791761875153\n",
      "Accuracy: 0.9502\n",
      "Pred shape: (10000,)\n",
      "Trainset: 53\n",
      "Training loss: 0.001040847685188055\n",
      "Test loss: 0.1650206465125084\n",
      "Accuracy: 0.9544\n",
      "Pred shape: (10000,)\n",
      "Trainset: 54\n",
      "Training loss: 0.0008562108185142279\n",
      "Test loss: 0.15665515761375426\n",
      "Accuracy: 0.9563\n",
      "Pred shape: (10000,)\n",
      "Trainset: 55\n",
      "Training loss: 0.0015048275887966157\n",
      "Test loss: 0.15689997526407243\n",
      "Accuracy: 0.9545\n",
      "Pred shape: (10000,)\n",
      "Trainset: 56\n",
      "Training loss: 0.0010565139744430781\n",
      "Test loss: 0.17323768299818038\n",
      "Accuracy: 0.9526\n",
      "Pred shape: (10000,)\n",
      "Trainset: 57\n",
      "Training loss: 0.0015532653108239175\n",
      "Test loss: 0.16488285521268845\n",
      "Accuracy: 0.9543\n",
      "Pred shape: (10000,)\n",
      "Trainset: 58\n",
      "Training loss: 0.0019234621971845626\n",
      "Test loss: 0.16258742256164552\n",
      "Accuracy: 0.9536\n",
      "Pred shape: (10000,)\n",
      "Trainset: 59\n",
      "Training loss: 0.00122217658162117\n",
      "Test loss: 0.16289391282796858\n",
      "Accuracy: 0.9561\n",
      "Pred shape: (10000,)\n",
      "Trainset: 60\n",
      "Training loss: 0.0015784113928675651\n",
      "Test loss: 0.1497489895105362\n",
      "Accuracy: 0.9561\n",
      "Pred shape: (10000,)\n",
      "Trainset: 61\n",
      "Training loss: 0.00116826241184026\n",
      "Test loss: 0.1592061168193817\n",
      "Accuracy: 0.9542\n",
      "Pred shape: (10000,)\n",
      "Trainset: 62\n",
      "Training loss: 0.0012175716906785965\n",
      "Test loss: 0.16052997921705245\n",
      "Accuracy: 0.956\n",
      "Pred shape: (10000,)\n",
      "Trainset: 63\n",
      "Training loss: 0.0009315860122442245\n",
      "Test loss: 0.1621150666117668\n",
      "Accuracy: 0.9565\n",
      "Pred shape: (10000,)\n",
      "Trainset: 64\n",
      "Training loss: 0.0014934733770787716\n",
      "Test loss: 0.1557580372452736\n",
      "Accuracy: 0.9564\n",
      "Pred shape: (10000,)\n",
      "Trainset: 65\n",
      "Training loss: 0.0010919310450553893\n",
      "Test loss: 0.15005274343490602\n",
      "Accuracy: 0.9597\n",
      "Pred shape: (10000,)\n",
      "Trainset: 66\n",
      "Training loss: 0.0016993383839726448\n",
      "Test loss: 0.18614236155748368\n",
      "Accuracy: 0.9478\n",
      "Pred shape: (10000,)\n",
      "Trainset: 67\n",
      "Training loss: 0.0011284622848033905\n",
      "Test loss: 0.16260680066347122\n",
      "Accuracy: 0.9529\n",
      "Pred shape: (10000,)\n",
      "Trainset: 68\n",
      "Training loss: 0.0015036766231060028\n",
      "Test loss: 0.15851781665086745\n",
      "Accuracy: 0.9569\n",
      "Pred shape: (10000,)\n",
      "Trainset: 69\n",
      "Training loss: 0.0011953541189432145\n",
      "Test loss: 0.16760014253854752\n",
      "Accuracy: 0.9553\n",
      "Pred shape: (10000,)\n",
      "Trainset: 70\n",
      "Training loss: 0.0008263150677084922\n",
      "Test loss: 0.17364321357011794\n",
      "Accuracy: 0.9548\n",
      "Pred shape: (10000,)\n",
      "Trainset: 71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011947111040353775\n",
      "Test loss: 0.16877378964424133\n",
      "Accuracy: 0.9513\n",
      "Pred shape: (10000,)\n",
      "Trainset: 72\n",
      "Training loss: 0.0009462346956133843\n",
      "Test loss: 0.16878813257217407\n",
      "Accuracy: 0.9533\n",
      "Pred shape: (10000,)\n",
      "Trainset: 73\n",
      "Training loss: 0.0012289856374263764\n",
      "Test loss: 0.16307987217903136\n",
      "Accuracy: 0.958\n",
      "Pred shape: (10000,)\n",
      "Trainset: 74\n",
      "Training loss: 0.001612268254160881\n",
      "Test loss: 0.17386366680860518\n",
      "Accuracy: 0.9536\n",
      "Pred shape: (10000,)\n",
      "Trainset: 75\n",
      "Training loss: 0.002413927190005779\n",
      "Test loss: 0.2039376142859459\n",
      "Accuracy: 0.9428\n",
      "Pred shape: (10000,)\n",
      "Trainset: 76\n",
      "Training loss: 0.0015791537016630172\n",
      "Test loss: 0.1477013156056404\n",
      "Accuracy: 0.9582\n",
      "Pred shape: (10000,)\n",
      "Trainset: 77\n",
      "Training loss: 0.000991596095263958\n",
      "Test loss: 0.15542731709480287\n",
      "Accuracy: 0.9577\n",
      "Pred shape: (10000,)\n",
      "Trainset: 78\n",
      "Training loss: 0.0007409594282507897\n",
      "Test loss: 0.16518702783584593\n",
      "Accuracy: 0.9555\n",
      "Pred shape: (10000,)\n",
      "Trainset: 79\n",
      "Training loss: 0.0015107122361660004\n",
      "Test loss: 0.1656525731086731\n",
      "Accuracy: 0.9571\n",
      "Pred shape: (10000,)\n",
      "Trainset: 80\n",
      "Training loss: 0.0014173092544078826\n",
      "Test loss: 0.15065702917575835\n",
      "Accuracy: 0.9616\n",
      "Pred shape: (10000,)\n",
      "Trainset: 81\n",
      "Training loss: 0.0011279438510537147\n",
      "Test loss: 0.15110381457805633\n",
      "Accuracy: 0.9578\n",
      "Pred shape: (10000,)\n",
      "Trainset: 82\n",
      "Training loss: 0.0010966930165886878\n",
      "Test loss: 0.14639048738479615\n",
      "Accuracy: 0.9607\n",
      "Pred shape: (10000,)\n",
      "Trainset: 83\n",
      "Training loss: 0.000978833992034197\n",
      "Test loss: 0.14113880978822707\n",
      "Accuracy: 0.961\n",
      "Pred shape: (10000,)\n",
      "Trainset: 84\n",
      "Training loss: 0.001152585454285145\n",
      "Test loss: 0.14808851916790008\n",
      "Accuracy: 0.961\n",
      "Pred shape: (10000,)\n",
      "Trainset: 85\n",
      "Training loss: 0.0004927893429994584\n",
      "Test loss: 0.14032890001535417\n",
      "Accuracy: 0.9633\n",
      "Pred shape: (10000,)\n",
      "Trainset: 86\n",
      "Training loss: 0.0011917577411513776\n",
      "Test loss: 0.155116239631176\n",
      "Accuracy: 0.959\n",
      "Pred shape: (10000,)\n",
      "Trainset: 87\n",
      "Training loss: 0.0014080082625150681\n",
      "Test loss: 0.164393237555027\n",
      "Accuracy: 0.9542\n",
      "Pred shape: (10000,)\n",
      "Trainset: 88\n",
      "Training loss: 0.0016024160385131837\n",
      "Test loss: 0.14036702855825425\n",
      "Accuracy: 0.9604\n",
      "Pred shape: (10000,)\n",
      "Trainset: 89\n",
      "Training loss: 0.0009894390515983104\n",
      "Test loss: 0.15302435281276702\n",
      "Accuracy: 0.9592\n",
      "Pred shape: (10000,)\n",
      "Trainset: 90\n",
      "Training loss: 0.0009779689460992812\n",
      "Test loss: 0.1407322503566742\n",
      "Accuracy: 0.9622\n",
      "Pred shape: (10000,)\n",
      "Trainset: 91\n",
      "Training loss: 0.0007503823712468147\n",
      "Test loss: 0.14135208469629287\n",
      "Accuracy: 0.961\n",
      "Pred shape: (10000,)\n",
      "Trainset: 92\n",
      "Training loss: 0.0007149771824479103\n",
      "Test loss: 0.1515458855867386\n",
      "Accuracy: 0.9617\n",
      "Pred shape: (10000,)\n",
      "Trainset: 93\n",
      "Training loss: 0.0016169355493038892\n",
      "Test loss: 0.15651664156913758\n",
      "Accuracy: 0.9599\n",
      "Pred shape: (10000,)\n",
      "Trainset: 94\n",
      "Training loss: 0.001492156319320202\n",
      "Test loss: 0.1376002704024315\n",
      "Accuracy: 0.9631\n",
      "Pred shape: (10000,)\n",
      "Trainset: 95\n",
      "Training loss: 0.000865586131811142\n",
      "Test loss: 0.15137550778388978\n",
      "Accuracy: 0.9574\n",
      "Pred shape: (10000,)\n",
      "Trainset: 96\n",
      "Training loss: 0.0015715878531336784\n",
      "Test loss: 0.1614065178990364\n",
      "Accuracy: 0.9536\n",
      "Pred shape: (10000,)\n",
      "Trainset: 97\n",
      "Training loss: 0.0011980872303247452\n",
      "Test loss: 0.13245773459672927\n",
      "Accuracy: 0.9629\n",
      "Pred shape: (10000,)\n",
      "Trainset: 98\n",
      "Training loss: 0.0011126929149031638\n",
      "Test loss: 0.15911959685087204\n",
      "Accuracy: 0.9581\n",
      "Pred shape: (10000,)\n",
      "Trainset: 99\n",
      "Training loss: 0.001180731236934662\n",
      "Test loss: 0.16120994642972947\n",
      "Accuracy: 0.9571\n",
      "Pred shape: (10000,)\n",
      "Trainset: 100\n",
      "Training loss: 0.0015908578485250473\n",
      "Test loss: 0.16015511800050736\n",
      "Accuracy: 0.9569\n",
      "Pred shape: (10000,)\n",
      "Preds shape: (100, 10000)\n"
     ]
    }
   ],
   "source": [
    "# *********** Train the model **********\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "   \n",
    "model.to(device)\n",
    "\n",
    "epochs = 5\n",
    "step = 0\n",
    "\n",
    "preds = []\n",
    "\n",
    "for i in range(num_teachers):\n",
    "    print('Trainset:', i+1)\n",
    "    pred = []\n",
    "\n",
    "    for e in range(epochs):\n",
    "        #print('Epoch:', e+1)\n",
    "        running_loss = 0\n",
    "        trainloader = torch.utils.data.DataLoader(trainsets[i], batch_size=64, shuffle=True)\n",
    "        \n",
    "        for imgs, labels in trainloader:\n",
    "            step += 1\n",
    "            imgs = imgs.view(imgs.shape[0], -1)\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logps = model(imgs)\n",
    "            loss = criterion(logps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            accuracy  = 0\n",
    "\n",
    "            for imgs, labels in testloader:\n",
    "                imgs = imgs.view(imgs.shape[0], -1)\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "                logps = model(imgs)\n",
    "                loss = criterion(logps, labels)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                ps = torch.exp(logps)\n",
    "                top_ps, top_class = ps.topk(1, dim=1)\n",
    "                equality = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equality.type(torch.FloatTensor)).item()\n",
    "\n",
    "                pred.append(top_class.cpu().flatten())\n",
    "        model.train()\n",
    "\n",
    "        print( 'Training loss:', running_loss/(epochs*num_teachers) )\n",
    "        print( 'Test loss:', test_loss/len(testloader) )\n",
    "        print( 'Accuracy:', accuracy/len(testloader) )\n",
    "\n",
    "    preds.append( np.array(pred) )\n",
    "    print('Pred shape:', np.array(pred).shape)\n",
    "preds = np.array(preds)\n",
    "print('Preds shape:', preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********** NEW Labels **********\n",
    "from syft.frameworks.torch.differential_privacy import pate\n",
    "\n",
    "new_labels = []\n",
    "pred = preds.transpose()\n",
    "\n",
    "for image in pred:\n",
    "    label_counts = np.bincount(image, minlength=num_labels)\n",
    "    \n",
    "    epsilon = 0.1\n",
    "    beta = 1/epsilon\n",
    "    \n",
    "    for i in range(len(label_counts)):\n",
    "        label_counts[i] += np.random.laplace(0, beta, 1)\n",
    "        \n",
    "    new_label = np.argmax(label_counts)  \n",
    "    new_labels.append(new_label)\n",
    "\n",
    "#new_labels       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Independent Epsilon: 411.5129254649703\n",
      "Data Dependent Epsilon: 55.18300925477453\n"
     ]
    }
   ],
   "source": [
    "# *********** PATE analysis **********\n",
    "data_dep_eps, data_ind_eps = pate.perform_analysis(teacher_preds=pred.transpose(),\n",
    "                                                   indices=np.array(new_labels),\n",
    "                                                   noise_eps=0.1,\n",
    "                                                   delta=1e-5)\n",
    "\n",
    "print(\"Data Independent Epsilon:\", data_ind_eps)\n",
    "print(\"Data Dependent Epsilon:\", data_dep_eps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
