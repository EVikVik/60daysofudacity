{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13026cdd8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Section Project:\n",
    "# For the final project for this section, you're going to train a DP model using this PATE method on the MNIST dataset, provided below.\n",
    "\n",
    "# *********** Load the data **********\n",
    "import torch\n",
    "from torch import nn\n",
    "import helper\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_testset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(mnist_trainset,batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(mnist_testset,batch_size=64)\n",
    "\n",
    "# *********** Check the data **********\n",
    "img, label = next(iter(testloader))\n",
    "helper.imshow(img[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# *********** Part from the exercise **********\n",
    "# TODO how can I use it?\n",
    "train_data = mnist_trainset.data\n",
    "train_targets = mnist_trainset.targets\n",
    "\n",
    "print(train_data.shape)\n",
    "\n",
    "test_data = mnist_trainset.data\n",
    "test_targets = mnist_trainset.targets\n",
    "\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_examples: 60000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# *********** Prepare input for PATH analysis **********\n",
    "num_teachers = 100\n",
    "num_examples = len(mnist_trainset)\n",
    "num_labels = 10\n",
    "\n",
    "lengths  = [len(mnist_trainset)//num_teachers]*num_teachers\n",
    "trainsets = torch.utils.data.random_split(mnist_trainset, lengths)\n",
    "\n",
    "print('num_examples:', num_examples)\n",
    "len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********** Create the model **********\n",
    "from collections import OrderedDict\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('fc1',  nn.Linear(784, 512)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('drop', nn.Dropout(p=0.2)),\n",
    "    ('fc2',  nn.Linear(512, 128)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('fc3',  nn.Linear(128, 10)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset: 0\n",
      "Training loss: 0.012487928010523319\n",
      "Test loss: 0.2594364644235866\n",
      "Accuracy: 0.9452627388535032\n",
      "Training loss: 0.0024955584364943204\n",
      "Test loss: 0.21162161297479254\n",
      "Accuracy: 0.9553144904458599\n",
      "Training loss: 0.000900308690033853\n",
      "Test loss: 0.21246595704441618\n",
      "Accuracy: 0.9537221337579618\n",
      "Trainset: 1\n",
      "Training loss: 0.0028604119084775447\n",
      "Test loss: 0.20023929261288065\n",
      "Accuracy: 0.9564092356687898\n",
      "Training loss: 0.0003781065344810486\n",
      "Test loss: 0.20491542092933776\n",
      "Accuracy: 0.9552149681528662\n",
      "Training loss: 0.0001850651454878971\n",
      "Test loss: 0.22354115147119874\n",
      "Accuracy: 0.9511345541401274\n",
      "Trainset: 2\n",
      "Training loss: 0.0021166251105023547\n",
      "Test loss: 0.21345457012296482\n",
      "Accuracy: 0.9545183121019108\n",
      "Training loss: 0.0008040024596266449\n",
      "Test loss: 0.23464136784243736\n",
      "Accuracy: 0.9507364649681529\n",
      "Training loss: 0.00037728483555838466\n",
      "Test loss: 0.2052653792557443\n",
      "Accuracy: 0.9552149681528662\n",
      "Trainset: 3\n",
      "Training loss: 0.0033617834001779556\n",
      "Test loss: 0.25942441901773405\n",
      "Accuracy: 0.9464570063694268\n",
      "Training loss: 0.0007520216563716531\n",
      "Test loss: 0.21647988262165124\n",
      "Accuracy: 0.9541202229299363\n",
      "Training loss: 0.00045879028737545014\n",
      "Test loss: 0.22241271524482473\n",
      "Accuracy: 0.955015923566879\n",
      "Trainset: 4\n",
      "Training loss: 0.0037680957466363907\n",
      "Test loss: 0.22794340650556952\n",
      "Accuracy: 0.9516321656050956\n",
      "Training loss: 0.0011147408932447433\n",
      "Test loss: 0.24072326733997673\n",
      "Accuracy: 0.9532245222929936\n",
      "Training loss: 0.0007916717231273651\n",
      "Test loss: 0.2560919787094092\n",
      "Accuracy: 0.9517316878980892\n",
      "Trainset: 5\n",
      "Training loss: 0.01637441884726286\n",
      "Test loss: 0.34223645811627623\n",
      "Accuracy: 0.9297372611464968\n",
      "Training loss: 0.009517081305384636\n",
      "Test loss: 0.3137460693147532\n",
      "Accuracy: 0.9339171974522293\n",
      "Training loss: 0.006004102304577827\n",
      "Test loss: 0.2226425267423794\n",
      "Accuracy: 0.9495421974522293\n",
      "Trainset: 6\n",
      "Training loss: 0.014392777755856513\n",
      "Test loss: 0.19792217258245323\n",
      "Accuracy: 0.9554140127388535\n",
      "Training loss: 0.004890868663787842\n",
      "Test loss: 0.26190244719670835\n",
      "Accuracy: 0.9403861464968153\n",
      "Training loss: 0.0023204532521776855\n",
      "Test loss: 0.22545513216477292\n",
      "Accuracy: 0.9487460191082803\n",
      "Trainset: 7\n",
      "Training loss: 0.012940485328435898\n",
      "Test loss: 0.20482672432995147\n",
      "Accuracy: 0.9517316878980892\n",
      "Training loss: 0.007153957113623619\n",
      "Test loss: 0.191588924877393\n",
      "Accuracy: 0.9541202229299363\n",
      "Training loss: 0.003528684228658676\n",
      "Test loss: 0.21704715708638453\n",
      "Accuracy: 0.9454617834394905\n",
      "Trainset: 8\n",
      "Training loss: 0.01172077128663659\n",
      "Test loss: 0.22035662163120168\n",
      "Accuracy: 0.9459593949044586\n",
      "Training loss: 0.004410838186740876\n",
      "Test loss: 0.20164981975581994\n",
      "Accuracy: 0.9524283439490446\n",
      "Training loss: 0.0022288138419389726\n",
      "Test loss: 0.22910274569965472\n",
      "Accuracy: 0.946656050955414\n",
      "Trainset: 9\n",
      "Training loss: 0.01046795666217804\n",
      "Test loss: 0.22696222032711005\n",
      "Accuracy: 0.9498407643312102\n",
      "Training loss: 0.007042550519108772\n",
      "Test loss: 0.20429958298707465\n",
      "Accuracy: 0.9553144904458599\n",
      "Training loss: 0.0037320956075564027\n",
      "Test loss: 0.25634220138097263\n",
      "Accuracy: 0.9461584394904459\n",
      "Trainset: 10\n",
      "Training loss: 0.01385044164955616\n",
      "Test loss: 0.24600950842070732\n",
      "Accuracy: 0.9442675159235668\n",
      "Training loss: 0.0038290707394480704\n",
      "Test loss: 0.227998255757959\n",
      "Accuracy: 0.946656050955414\n",
      "Training loss: 0.0026646549627184868\n",
      "Test loss: 0.2710592729175926\n",
      "Accuracy: 0.9411823248407644\n",
      "Trainset: 11\n",
      "Training loss: 0.013606116594746708\n",
      "Test loss: 0.24932527010607872\n",
      "Accuracy: 0.9479498407643312\n",
      "Training loss: 0.004331320598721504\n",
      "Test loss: 0.25503131457764633\n",
      "Accuracy: 0.9394904458598726\n",
      "Training loss: 0.0024936368595808744\n",
      "Test loss: 0.2555178020885036\n",
      "Accuracy: 0.9492436305732485\n",
      "Trainset: 12\n",
      "Training loss: 0.015201995372772217\n",
      "Test loss: 0.18027161690554802\n",
      "Accuracy: 0.9551154458598726\n",
      "Training loss: 0.006878173053264618\n",
      "Test loss: 0.21018401882166315\n",
      "Accuracy: 0.9473527070063694\n",
      "Training loss: 0.0026421963050961496\n",
      "Test loss: 0.19537855689502825\n",
      "Accuracy: 0.9522292993630573\n",
      "Trainset: 13\n",
      "Training loss: 0.0171710417419672\n",
      "Test loss: 0.1963588203878919\n",
      "Accuracy: 0.950437898089172\n",
      "Training loss: 0.005705919079482555\n",
      "Test loss: 0.1979333755744111\n",
      "Accuracy: 0.9513335987261147\n",
      "Training loss: 0.0027865060931071637\n",
      "Test loss: 0.187368596103161\n",
      "Accuracy: 0.9523288216560509\n",
      "Trainset: 14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-816e9b849ea6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0maccuracy\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                     \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pysyft/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pysyft/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pysyft/lib/python3.6/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pysyft/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pysyft/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/pysyft/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# *********** Train the model **********\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "   \n",
    "model.to(device)\n",
    "\n",
    "epochs = 3\n",
    "step = 0\n",
    "print_every = 100\n",
    "# TODO ...\n",
    "for ii in range(num_teachers):\n",
    "    print('Trainset:', ii)\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        trainloader = torch.utils.data.DataLoader(trainsets[ii], batch_size=64, shuffle=True)\n",
    "        for imgs, labels in trainloader:\n",
    "            step += 1\n",
    "            imgs = imgs.view(imgs.shape[0], -1)\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logps = model(imgs)\n",
    "            loss = criterion(logps, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                test_loss = 0\n",
    "                accuracy  = 0\n",
    "                \n",
    "                for imgs, labels in testloader:\n",
    "                    imgs = imgs.view(imgs.shape[0], -1)\n",
    "                    imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "                    logps = model(imgs)\n",
    "                    loss = criterion(logps, labels)\n",
    "                    test_loss += loss.item()\n",
    "\n",
    "                    ps = torch.exp(logps)\n",
    "                    top_ps, top_class = ps.topk(1, dim=1)\n",
    "                    equality = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equality.type(torch.FloatTensor)).item()\n",
    "\n",
    "            print('Training loss:', running_loss/print_every)\n",
    "            print('Test loss:', test_loss/len(testloader))\n",
    "            print('Accuracy:', accuracy/len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *********** PATE analysis **********\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data_dep_eps, data_ind_eps = pate.perform_analysis(teacher_preds=preds, indices=indices, noise_eps=0.1, delta=1e-5, moments=20)\n",
    "#print(\"Data Independent Epsilon:\", data_ind_eps)\n",
    "#print(\"Data Dependent Epsilon:\", data_dep_eps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
