{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\nW0714 18:17:01.096807 4321358720 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0714 18:17:01.124337 4321358720 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "from torch import nn, optim\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset initialisation\n",
    "data = th.tensor([[1.,1],[0,1],[1,0],[0,0]], requires_grad=True)\n",
    "target = th.tensor([[1.],[1], [0], [0]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VirtualWorkers initialisation\n",
    "hook = sy.TorchHook(th)\n",
    "\n",
    "bob     = sy.VirtualWorker(hook, id='bob')\n",
    "alice   = sy.VirtualWorker(hook, id='alice')\n",
    "central = sy.VirtualWorker(hook, id='central')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bob before: {81965632757: tensor([[1., 1.],\n        [0., 1.]], requires_grad=True), 30760523774: tensor([[1.],\n        [1.]], requires_grad=True)}\nalice before: {72883206436: tensor([[1., 0.],\n        [0., 0.]], requires_grad=True), 4994224652: tensor([[0.],\n        [0.]], requires_grad=True)}\ncentral before: {}\n"
     ]
    }
   ],
   "source": [
    "# Data sending\n",
    "bob.clear_objects()\n",
    "alice.clear_objects()\n",
    "central.clear_objects()\n",
    "\n",
    "data_bob   = data[:2].send(bob)\n",
    "data_alice = data[2:].send(alice)\n",
    "\n",
    "target_bob   = target[:2].send(bob)\n",
    "target_alice = target[2:].send(alice)\n",
    "\n",
    "print('bob before:',     bob._objects)\n",
    "print('alice before:',   alice._objects)\n",
    "print('central before:', central._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.2982)\ntensor(0.0798)\ntensor(0.0011)\ntensor(0.0004)\ntensor(0.0004)\ntensor(0.0003)\ntensor(0.0003)\ntensor(0.0002)\ntensor(0.0002)\ntensor(0.0001)\ntensor(0.0001)\ntensor(0.0001)\ntensor(8.3802e-05)\ntensor(6.9749e-05)\ntensor(5.8053e-05)\ntensor(4.8318e-05)\ntensor(4.0215e-05)\ntensor(3.3471e-05)\ntensor(2.7859e-05)\ntensor(2.3188e-05)\nbob: {81965632757: tensor([[1., 1.],\n        [0., 1.]], requires_grad=True), 30760523774: tensor([[1.],\n        [1.]], requires_grad=True)}\ncentral: {47636388032: Parameter containing:\ntensor([[-0.0062,  0.5717]], requires_grad=True), 12871416100: Parameter containing:\ntensor([0.4318], requires_grad=True)}\ntensor(0.1510)\ntensor(0.0384)\ntensor(0.0122)\ntensor(0.0057)\ntensor(0.0038)\ntensor(0.0030)\ntensor(0.0025)\ntensor(0.0021)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0018)\ntensor(0.0016)\ntensor(0.0013)\ntensor(0.0011)\ntensor(0.0010)\ntensor(0.0008)\ntensor(0.0007)\ntensor(0.0006)\ntensor(0.0005)\ntensor(0.0004)\ntensor(0.0004)\ntensor(0.0003)\nalice: {72883206436: tensor([[1., 0.],\n        [0., 0.]], requires_grad=True), 4994224652: tensor([[0.],\n        [0.]], requires_grad=True)}\ncentral: {47636388032: Parameter containing:\ntensor([[-0.0062,  0.5717]], requires_grad=True), 12871416100: Parameter containing:\ntensor([0.4318], requires_grad=True), 73691493462: Parameter containing:\ntensor([[ 0.0227, -0.6195]], requires_grad=True), 779146013: Parameter containing:\ntensor([-0.0140], requires_grad=True)}\n"
     ]
    }
   ],
   "source": [
    "def train(_data, _target, iterations=20):\n",
    "    # send model to the data\n",
    "    model = nn.Linear(2, 1).copy().send(_data.location)\n",
    "    \n",
    "    opt = optim.SGD(params=model.parameters(), lr=0.1)\n",
    "\n",
    "    for iter in range(iterations):            \n",
    "        # do normal training\n",
    "        opt.zero_grad()\n",
    "        pred = model(_data)\n",
    "                    \n",
    "        loss = ((pred - _target)**2).sum()\n",
    "        loss.backward()\n",
    "                    \n",
    "        opt.step()\n",
    "        print(loss.get().data)\n",
    "\n",
    "    model.move(central)\n",
    "\n",
    "train(data_bob, target_bob)\n",
    "print('bob:', bob._objects)\n",
    "print('central:', central._objects)\n",
    "train(data_alice, target_alice)\n",
    "print('alice:', alice._objects)\n",
    "print('central:', central._objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight before:  Parameter containing:\ntensor([[-0.4742,  0.3885]], requires_grad=True)\nbias before:  Parameter containing:\ntensor([-0.6204], requires_grad=True)\nweight after:  Parameter containing:\ntensor([[ 0.0083, -0.0239]], requires_grad=True)\nbias after:  Parameter containing:\ntensor([0.2089], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=1, bias=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the result on central server\n",
    "def model():\n",
    "    model = nn.Linear(2, 1)\n",
    "    \n",
    "    print('weight before: ', model.weight)\n",
    "    print('bias before: ', model.bias)\n",
    "    \n",
    "    length = len(central._objects) // 2\n",
    "    \n",
    "    weight = th.Tensor(1, 2)\n",
    "    bias   = th.Tensor(1)\n",
    "    \n",
    "    for  _, value in central._objects.items():\n",
    "        if value.size() == weight.size():\n",
    "            weight += value\n",
    "        else:\n",
    "            bias += value\n",
    "    \n",
    "    weight /= length\n",
    "    bias   /= length\n",
    "    \n",
    "    with th.no_grad():\n",
    "        model.weight.set_(weight)\n",
    "        model.bias.set_(bias)\n",
    "    \n",
    "    print('weight after: ', model.weight)\n",
    "    print('bias after: ', model.bias)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
